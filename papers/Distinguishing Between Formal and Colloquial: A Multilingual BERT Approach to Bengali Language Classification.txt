Distinguishing Between Formal and Colloquial: A Multilingual BERT Approach to Bengali Language Classification
Abstract—The Bengali language, rich in history and  cultural significance, poses unique challenges in Natu- ral Language Processing (NLP) due to its dual-register  structure: Sadhu (formal) and Cholit (colloquial).  These registers differ significantly in syntax, vocabu- lary, and usage, complicating tasks such as text classi- fication, translation, and sentiment analysis. Language  models not specifically trained to recognize these dis- tinctions often misinterpret these variations, limiting  the accuracy of Bengali NLP tools. To address this, a dataset from Mendeley was used to fine-tune the multilingual BERT (mBERT) model for distinguishing between Sadhu and Cholit registers. The fine-tuned model achieved an accuracy of 94.08%, effectively capturing the subtle lexical and syntactic differences between the two forms. This work advances Bengali NLP, enabling more precise applications in digital communication, automated translation, and linguistic analysis, while contributing to broader advancements in low-resource language processing.

Keywords—Bengali Language Classification, Sadhu and Cholit Registers, Low-Resource Language Processing, Natural Language Processing (NLP), Transformer-
Based Models, Multilingual BERT (mBERT).

Conclusion:
This study introduced a methodology for classifying Bengali sentences into Sadhu and Cholit forms using a multilingual BERT model. The experimental evaluation achieved an impressive accuracy of 94.08%, highlighting the model’s effectiveness in distinguishing between these two linguistic registers. The confusion matrix analysis  indicates strong performance across both classes with min- imal misclassifications. The steady decline observed in the  training and validation loss curves confirms the model’s ability to learn effectively from the training data while avoiding significant overfitting. These findings contribute  significantly to the field of Bengali Natural Language Pro- cessing (NLP) by offering a robust framework for register classification. This framework has practical implications for applications such as automated translation, digital communication, and linguistic analysis. Expanding the dataset to include more diverse examples of Sadhu and Cholit forms could enhance model robustness. Further  optimization could be achieved by exploring alternative ar- chitectures or fine-tuning methods. Applying this method- ology to other South Asian languages with similar linguis- tic characteristics represents another promising direction  for future research. The results demonstrate the feasibil- ity and potential of using transformer-based models for  tackling complex language classification tasks in Bengali, paving the way for advancements in multilingual NLP applications.
